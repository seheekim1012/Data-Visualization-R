---
output:
  pdf_document: default
urlcolor: blue
header-includes:    
  - \usepackage{lastpage}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[CO, CE]{SEHEE KIM}
  - \fancyfoot[CO, CE]{\thepage \ of \pageref{LastPage}}
---

```{r setup, echo=FALSE, message=FALSE}
# Students: You probably shouldn't change any of the code in this chunk.

# These are the packages you will need for this activity
packages_needed <- c("tidyverse", "googledrive", "readxl", "janitor", 
                     "lubridate", "opendatatoronto", "ggthemes")

package.check <- lapply(
  packages_needed,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
    }
  }
)

# Credit: package.check based on a helpful post from Vikram Baliga https://vbaliga.github.io/verify-that-r-packages-are-installed-and-loaded/

# Load tidyverse
library(tidyverse)
library(readxl)
library(janitor)
library(opendatatoronto)
library(ggthemes)

# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), echo = TRUE)

```


```{r getdata, echo=FALSE, eval=FALSE}
# Students: You probably shouldn't change any of the code in this chunk BUT...

# This chunk loads the most recent data from Toronto City and the data from OpenToronto.

# You have to RUN this chunk by hand to update the data as 
#   eval is set to FALSE to limit unnecessary requsts on the site.

###################################################
# Step one: Get the COVID data from Toronto City. #
###################################################

googledrive::drive_deauth()

url1 <- "https://drive.google.com/file/d/11KF1DuN5tntugNc10ogQDzFnW05ruzLH/view"
googledrive::drive_download(url1, path="data/CityofToronto_COVID-19_Daily_Public_Reporting.xlsx", overwrite = TRUE)

url2 <- "https://drive.google.com/file/d/1jzH64LvFQ-UsDibXO0MOtvjbL2CvnV3N/view"
googledrive::drive_download(url2, path = "data/CityofToronto_COVID-19_NeighbourhoodData.xlsx", overwrite = TRUE)

# this removes the url object that we don't need anymore
rm(url1, url2)

#####################################################################
# Step two: Get the data neighbourhood data from Open Data Toronto. #
#####################################################################

nbhoods_shape_raw <- list_package_resources("neighbourhoods") %>% 
  get_resource()

saveRDS(nbhoods_shape_raw, "data/neighbourhood_shapefile.Rds")

nbhood_profile <- search_packages("Neighbourhood Profile") %>%
  list_package_resources() %>% 
  filter(name == "neighbourhood-profiles-2016-csv") %>% 
  get_resource()

saveRDS(nbhood_profile, "data/neighbourhood_profile.Rds")
```


```{r load_data, echo=FALSE}
######################################################
# Step three: Load the COVID data from Toronto City. #
######################################################

# Saving the name of the file as an object and then using the object name in the
# following code is a helpful practice. Why? If we change the name of the file 
# being used, we'll only have to change it in one place. This helps us avoid 
# 'human error'.

daily_data <- "data/CityofToronto_COVID-19_Daily_Public_Reporting.xlsx"

# Cases reported by date (double check the sheet is correct)
# Should be a sheet names something like  
## 'Cases by Reported Date'
reported_raw <- read_excel(daily_data, sheet = 6) %>% 
  clean_names()

# Cases by outbreak type (double check the sheet is correct)
# Should be a sheet names something like  
## 'Cases by Outbreak Type and Epis'
outbreak_raw <- read_excel(daily_data, sheet = 4) %>% 
  clean_names()

# When was this data updated?
date_daily <- read_excel(daily_data, sheet = 1) %>% 
  clean_names()
  

# By neighbourhood
neighbourood_data <- "data/CityofToronto_COVID-19_NeighbourhoodData.xlsx"

# Cases reported by date
nbhood_raw <- read_excel(neighbourood_data, sheet = 2) %>% 
  clean_names()

# Date the neighbourhood data was last updated
date_nbhood <- read_excel(neighbourood_data, sheet = 1) %>% 
  clean_names()

#don't need these anymore
rm(daily_data, neighbourood_data)

#############################################################
# Step four: Load the neighbourhood data from Toronto City. #
#############################################################

# Get neighbourhood profile data
nbhood_profile <- readRDS("data/neighbourhood_profile.Rds")

# Get shape data for mapping 
nbhoods_shape_raw <- readRDS("data/neighbourhood_shapefile.Rds") %>% 
  sf::st_as_sf() ## Makes sure shape info is in the most up to date format

```

Code last run `r Sys.Date()`.  
Daily: `r date_daily[1,1]`.   
Neighbourhood: `r date_nbhood[1,1]`. 

# Task 1: Daily cases
## Data wrangling

```{r cases_dw}
reported_raw %>% filter(is.na(episode_date))
# clean_reported <- reported_raw
# colnames(clean_reported) <- str_to_title(colnames(reported_raw))
# clean_reported$Episode_date <- date(clean_reported$Episode_date)

reported <- reported_raw %>% 
  mutate(episode_date = date(reported_raw$episode_date)) %>% 
  mutate_if(is.numeric,replace_na, replace=0) %>% 
  gather("Type", "Value", -episode_date) %>% 
  mutate(Type = case_when(
    Type== "active"~ "Active",
    Type== "recovered" ~"Recovered",
    Type == "deceased"~"Deceased"
  ) ) %>% 
  mutate(Type = fct_relevel(Type, "Deceased", after = 2))

```

\newpage
## Data visualization

```{r cases_vis}
reported %>% 
  ggplot(aes(x=episode_date, y =Value, fill= Type)) +
  geom_bar(stat = "identity", width = 1)+
  theme_minimal()+
  theme(legend.position = c(0.15,0.8),
        legend.title=element_blank())+
  scale_x_date(limits = c(date("2020-01-01"),Sys.Date()))+
  scale_fill_manual(values = c("#003f5c","#86bcB6","#b9ca5d"))+
  labs(title="Cases reported by day in Toronto, Canada", 
  subtitle="Confirmed and probable cases",
       x= "Case Count", y="Date", 
       caption = str_c("Created by: Sehee Kim for STA303/1002, UofT\n",
"Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n"
,date_daily[1,1]))
    
```

\newpage
# Task 2: Outbreak type
## Data wrangling


```{r outbreak_dw}
outbreak_raw %>% 
  filter(is.na(outbreak_or_sporadic)) %>% 
  filter(is.na(reported_week)) %>% 
  filter(is.na(cases))


outbreak <- outbreak_raw %>% 
  mutate(reported_week = date(outbreak_raw$reported_week)) %>%
  mutate(outbreak_or_sporadic = str_replace_all(outbreak_or_sporadic, "OB Associated", 
                                                "Outbreak associated")) %>% 
  rename(Outbreak_type = outbreak_or_sporadic) %>% 
  group_by(reported_week) %>% 
  mutate(total_cases = sum(cases)) %>% 
  mutate(Outbreak_type = fct_rev(Outbreak_type))

colnames(outbreak) <- str_to_title(colnames(outbreak))

```

\newpage
## Data visualization

```{r outbreak_vis}
#present_day_seven = parse_date_time(date_daily[1,1], orders= c("ymd", "dmy", "mdy"))

outbreak %>% 
  ggplot(aes(x=Reported_week, y= Cases, fill = Outbreak_type))+
  geom_bar(stat="identity", width=7)+
  theme_minimal()+
  theme(legend.position = c(0.15,0.8),
        legend.title=element_blank())+
  scale_x_date(limits = c(date("2020-01-01"),Sys.Date()+7))+
  scale_fill_manual(values = c("#86bcB6","#b9ca5d"))+
  labs(title="Cases reported by outbreak type in Toronto, Canada", 
       subtitle="Confirmed and probable cases",
       x= "Case Count", y="Date", 
       caption = str_c("Created by: Sehee Kim for STA303/1002, UofT\n",
"Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n"
,date_daily[1,1]))
    ```

\newpage
# Task 3: Neighbourhoods
## Data wrangling: part 1

```{r nbhood_dw_1}
income <- filter(nbhood_profile, nbhood_profile$Topic == "Low income in 2015", nbhood_profile$`_id` ==1143) %>%
  pivot_longer(-c(Characteristic,`_id`,Category,Topic,`Data Source`), 
               names_to = "neighbourhood_name", values_to="Percentage") %>% 
  select(-`_id`, -Category, -Topic, -`Data Source`, -Characteristic) %>% 
  mutate(Percentage=parse_number(Percentage, locale=locale(decimal_mark = ".", grouping_mark = " ")))
```

## Data wrangling: part 2

```{r nbhood_dw_2}
#glimpse(nbhoods_shape_raw)

#first see what happens if we join the data right away
nbhoods_all_try <- nbhoods_shape_raw %>% 
  mutate(neighbourhood_name = str_remove(AREA_NAME, "\\s\\(\\d+\\)*$")) %>% 
  left_join(income, by = "neighbourhood_name")

problems <- nbhoods_all_try %>% #typos
  filter(is.na(Percentage))

Rate_per_cases <- nbhood_raw %>% 
  select(-neighbourhood_id,-case_count) %>% 
  rename(rate_per_100000 = rate_per_100_000_people)

nbhoods_all <-nbhoods_shape_raw %>% 
  mutate(neighbourhood_name = str_remove(AREA_NAME, "\\s\\(\\d+\\)*$")) %>% 
  mutate(neighbourhood_name = case_when(
    str_detect(neighbourhood_name, "St.James") 
    ~ str_replace_all(neighbourhood_name, "St.James", "St. James"),
    neighbourhood_name == "Weston-Pellam Park"~ "Weston-Pelham Park",
    TRUE ~ neighbourhood_name
  )) %>% 
  left_join(income, by = "neighbourhood_name") %>% 
  left_join(Rate_per_cases, by = "neighbourhood_name") %>% 
  select(-X, -Y, -LONGITUDE,-LATITUDE,-PARENT_AREA_ID)

#check <- nbhoods_all %>%
  #filter(is.na(Percentage))
#colnames(nbhoods_all) <- str_to_title(colnames(nbhoods_all))

```

## Data wrangling: part 3

```{r nbhood_dw_3}
nbhoods_final <- nbhoods_all %>% 
  mutate(med_inc = median(Percentage)) %>% 
  mutate(med_rate = median(rate_per_100000)) %>% 
  mutate(nbhood_type = case_when(
    Percentage <= med_inc & rate_per_100000 <= med_rate ~ "Higher low income rate, higher case rate",
    Percentage <= med_inc & rate_per_100000 >= med_rate ~ "Higher low income rate, lower case rate",
    Percentage >= med_inc & rate_per_100000 <= med_rate ~ "Lower low income rate, higher case rate",
    Percentage >= med_inc & rate_per_100000 >= med_rate ~ "Lower low income rate, higher case rate"
  ))
```

\newpage
## Data visualization

```{r neighbourhood_graphs_1, fig.height=4, fig.width=6}
ggplot(data = nbhoods_final) +
  geom_sf(position = "identity", aes(fill= Percentage))+
  theme_map()+
  theme(legend.position = c(1.0,0.1))+
  scale_fill_gradient(name="% low income", low = "darkgreen", high = "lightgrey")+
  labs(title ="Percentage of 18 to 64 year olds living in a low income family (2015)",
       subtitle = "Neighbourhoods of Toronto, Canada",
       caption = str_c("Created by: Sehee Kim for STA303/1002, UofT\n",
       "Source: Census Profile 98-315-X2016001 via OpenData Toronto\n" 
       ,date_daily[1,1]))
```

\newpage

```{r neighbourhood_graphs_2, fig.height=4, fig.width=8}
ggplot(data = nbhoods_final) +
  geom_sf(aes(fill = rate_per_100000)) +
  theme_map() +
  theme(legend.position = c(1.0,0.1))+
  scale_fill_gradient(name="Cases per 100,000 people", low = "white", high = "darkorange")+
  labs(title ="COVID-19 cases per 100,000, by neighbourhood in Toronto, Canada",
       caption = str_c("Created by: Sehee Kim for STA303/1002, UofT \n",                       
 "Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n",
 date_daily[1,1]))
```

\newpage

```{r neighbourhood_graphs_3, fig.height=4, fig.width=9}
ggplot(data = nbhoods_final) +
  geom_sf(aes(fill = nbhood_type)) +
  theme_map() +
  theme(legend.position = c(1.0,0.0))+
  scale_fill_brewer(palette = "Set1", name = "% of 18 to 64 year-olds in \n low income families and \n COVID-19 case rates")+
  labs(title ="COVID-19 cases per 100,000, by neighbourhood in Toronto, Canada",
       caption = str_c("Created by: Sehee Kim for STA303/1002, UofT \n", 
      "Income data source: Census Profile 98-316-x2016001 via OpenData Toronto \n",
      "Source: Ontario Ministry of Health, Integrated Public Health Information System and CORES\n"
      ,date_daily[1,1]))
```




```{r include=FALSE, eval=FALSE}
# This chunk of code helps you prepare your assessment for submission on Crowdmark
# This is optional. If it isn't working, you can do it manually/take another approach.

# Run this chunk by hand after knitting your final version of your pdf for submission.
# A new file called 'to_submit' will appear in your working directory with each page of your assignment as a separate pdf.

# Install the required packages
if(!match("staplr", installed.packages()[,1], nomatch = FALSE))
  {install.packages("staplr")}

# Don't edit anything in this function
prep_for_crowdmark <- function(pdf=NULL){
  # Get the name of the file you're currently in. 
  this_file <- rstudioapi::getSourceEditorContext()$path
  pdf_name <- sub(".Rmd", ".pdf", sub('.*/', '', this_file))
  
  # Create a file called to_submit to put the individual files in
  # This will be in the same folder as this file is saved
  if(!match("to_submit", list.files(), nomatch = FALSE))
    {dir.create("to_submit")}
 
  # Split the files
  if(is.null(pdf)){
  staplr::split_pdf(pdf_name, output_directory = "to_submit", prefix = "page_")} else {
    staplr::split_pdf(pdf, output_directory = "to_submit", prefix = "page_") 
  }
}

prep_for_crowdmark()

```
